{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Summary\n",
    "This code gives a short summary on the current progress (last update: 17.12.19).\n",
    "In the following a CNN aswell as a FFNN are trained to learn the mapping HNG-Parameters (w,a,b,g*,h0) to HNG-Volatility surface. A first approach on  training the inverse mapping with CNN is given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preambel and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preambel\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import InputLayer,Dense,Flatten, Conv2D, Dropout, Input,ZeroPadding2D,MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "#import py_vollib.black_scholes.implied_volatility as vol\n",
    "#import time\n",
    "import scipy\n",
    "import scipy.io\n",
    "\n",
    "# scaler\n",
    "def ytransform(y_train,y_val,y_test):\n",
    "    #return [scale.transform(y_train),scale.transform(y_val), \n",
    "    #        scale.transform(y_test)]\n",
    "    return [y_train,y_val,y_test]\n",
    "\n",
    "def yinversetransform(y):\n",
    "    return y\n",
    "    #return scale.inverse_transform(y)\n",
    "    \n",
    "def myscale(x):\n",
    "    res=np.zeros(Nparameters)\n",
    "    for i in range(Nparameters):\n",
    "        res[i]=(x[i] - (ub[i] + lb[i])*0.5) * 2 / (ub[i] + lb[i])\n",
    "    return res\n",
    "\n",
    "def myinverse(x):\n",
    "    res=np.zeros(Nparameters)\n",
    "    for i in range(Nparameters):\n",
    "        res[i]=x[i]*(ub[i] + lb[i]) *0.5 + (ub[i] + lb[i])*0.5\n",
    "    return res\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))   \n",
    "def root_relative_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square((y_pred - y_true)/y_true)))    \n",
    "    \n",
    "# Data Import\n",
    "mat         = scipy.io.loadmat('data_vola_maxbounds_50000_0005_09_11_30_210.mat')\n",
    "data        = mat['data_vola']\n",
    "Nparameters = 5\n",
    "maturities  = np.array([30, 60, 90, 120, 150, 180, 210])\n",
    "strikes     = np.array([0.9, 0.925, 0.95, 0.975, 1.0, 1.025, 1.05, 1.075, 1.1])\n",
    "Nstrikes    = len(strikes)   \n",
    "Nmaturities = len(maturities)   \n",
    "xx          = data[:,:Nparameters]\n",
    "yy          = data[:,Nparameters+2:]\n",
    "\n",
    "ub=np.amax(xx, axis=0)\n",
    "lb=np.amin(xx, axis=0)\n",
    "\n",
    "# split into train and test sample\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    xx, yy, test_size=0.15)#, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "   X_train, y_train, test_size=0.15)#, random_state=42)\n",
    "\n",
    "Ntest= X_test.shape[0]\n",
    "Ntrain= X_train.shape[0]\n",
    "Nval= X_val.shape[0]\n",
    "keras.backend.set_floatx('float64')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN as Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping train/test sets for structure purposes\n",
    "[y_train_trafo, y_val_trafo, y_test_trafo]=ytransform(y_train, y_val, y_test)\n",
    "y_train_trafo = np.asarray([y_train[i,:].reshape((1,Nmaturities,Nstrikes)) for i in range(Ntrain)])\n",
    "y_val_trafo =  np.asarray([y_val[i,:].reshape((1,Nmaturities,Nstrikes)) for i in range(Nval)])\n",
    "y_test_trafo =  np.asarray([y_test[i,:].reshape((1,Nmaturities,Nstrikes)) for i in range(Ntest)])\n",
    "\n",
    "X_train_trafo = np.array([myscale(x) for x in X_train])\n",
    "X_val_trafo   = np.array([myscale(x) for x in X_val])\n",
    "X_test_trafo  = np.array([myscale(x) for x in X_test])\n",
    "X_train_trafo = np.array([myscale(x) for x in X_train])\n",
    "X_val_trafo   = np.array([myscale(x) for x in X_val])\n",
    "X_test_trafo  = X_test_trafo.reshape((Ntest,5,1,1))\n",
    "X_train_trafo = X_train_trafo.reshape((Ntrain,5,1,1))\n",
    "X_val_trafo   = X_val_trafo.reshape((Nval,5,1,1))\n",
    "\n",
    "NN1 = Sequential() \n",
    "NN1.add(InputLayer(input_shape=(Nparameters,1,1,)))\n",
    "NN1.add(ZeroPadding2D(padding=(2, 2)))\n",
    "NN1.add(Conv2D(32, (3, 1), padding='valid',strides =(1,1),activation='elu'))#X_train_trafo.shape[1:],activation='elu'))\n",
    "NN1.add(ZeroPadding2D(padding=(1,1)))\n",
    "NN1.add(Conv2D(32, (2, 2),padding='valid',strides =(1,1),activation ='elu'))\n",
    "NN1.add(Conv2D(32, (2, 2),padding='valid',strides =(2,1),activation ='elu'))\n",
    "NN1.add(ZeroPadding2D(padding=(1,1)))\n",
    "NN1.add(Conv2D(32, (3,3),padding='valid',strides =(2,1),activation ='elu'))\n",
    "NN1.add(ZeroPadding2D(padding=(1,1)))\n",
    "NN1.add(Conv2D(32, (2, 2),padding='valid',strides =(2,1),activation ='elu'))\n",
    "NN1.add(ZeroPadding2D(padding=(1,1)))\n",
    "NN1.add(Conv2D(32, (2, 2),padding='valid',strides =(2,1),activation ='elu'))\n",
    "#NN1.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "#NN1.add(Dropout(0.25))\n",
    "#NN1.add(ZeroPadding2D(padding=(0,1)))\n",
    "NN1.add(Conv2D(Nstrikes, (2, 1),padding='valid',strides =(2,1),activation ='linear', kernel_constraint = keras.constraints.NonNeg()))\n",
    "#NN1.add(MaxPooling2D(pool_size=(4, 1)))\n",
    "NN1.summary()\n",
    "NN1.compile(loss = root_relative_mean_squared_error, optimizer = \"adam\",metrics=[\"MAPE\",\"MSE\"])\n",
    "NN1.fit(X_train_trafo, y_train_trafo, batch_size=64, validation_data = (X_val_trafo, y_val_trafo),\n",
    "        epochs = 50, verbose = True, shuffle=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Results \n",
    "The following plots show the performance on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error plots\n",
    "S0=1.\n",
    "y_test_re    = yinversetransform(y_test_trafo).reshape((Ntest,Nmaturities,Nstrikes))\n",
    "prediction   = NN1.predict(X_test_trafo).reshape((Ntest,Nmaturities,Nstrikes))\n",
    "err_rel_mat  = np.zeros(prediction.shape)\n",
    "err_mat      = np.zeros(prediction.shape)\n",
    "for i in range(Ntest):\n",
    "    err_rel_mat[i,:,:] =  np.abs((y_test_re[i,:,:]-prediction[i,:,:])/y_test_re[i,:,:])\n",
    "    err_mat[i,:,:] =  np.square((y_test_re[i,:,:]-prediction[i,:,:]))\n",
    "idx = np.argsort(np.max(err_rel_mat,axis=tuple([1,2])), axis=None)\n",
    "\n",
    "#bad_idx = idx[:-200]\n",
    "bad_idx = idx\n",
    "#from matplotlib.colors import LogNorm\n",
    "plt.figure(figsize=(14,4))\n",
    "ax=plt.subplot(2,3,1)\n",
    "err1 = 100*np.mean(err_rel_mat[bad_idx,:,:],axis=0)\n",
    "plt.title(\"Average relative error\",fontsize=15,y=1.04)\n",
    "plt.imshow(err1)#,norm=LogNorm(vmin=err1.min(), vmax=err1.max()))\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.colorbar(format=mtick.PercentFormatter())\n",
    "ax.set_xticks(np.linspace(0,Nstrikes-1,Nstrikes))\n",
    "ax.set_xticklabels(strikes)\n",
    "ax.set_yticks(np.linspace(0,Nmaturities-1,Nmaturities))\n",
    "ax.set_yticklabels(maturities)\n",
    "plt.xlabel(\"Strike\",fontsize=15,labelpad=5)\n",
    "plt.ylabel(\"Maturity\",fontsize=15,labelpad=5)\n",
    "ax=plt.subplot(2,3,2)\n",
    "err2 = 100*np.std(err_rel_mat[bad_idx,:,:],axis = 0)\n",
    "plt.title(\"Std relative error\",fontsize=15,y=1.04)\n",
    "plt.imshow(err2)#,norm=LogNorm(vmin=err2.min(), vmax=err2.max()))\n",
    "plt.colorbar(format=mtick.PercentFormatter())\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "ax.set_xticks(np.linspace(0,Nstrikes-1,Nstrikes))\n",
    "ax.set_xticklabels(strikes)\n",
    "ax.set_yticks(np.linspace(0,Nmaturities-1,Nmaturities))\n",
    "ax.set_yticklabels(maturities)\n",
    "plt.xlabel(\"Strike\",fontsize=15,labelpad=5)\n",
    "plt.ylabel(\"Maturity\",fontsize=15,labelpad=5)\n",
    "ax=plt.subplot(2,3,3)\n",
    "err3 = 100*np.max(err_rel_mat[bad_idx,:,:],axis = 0)\n",
    "plt.title(\"Maximum relative error\",fontsize=15,y=1.04)\n",
    "plt.imshow(err3)#,norm=LogNorm(vmin=err3.min(), vmax=err3.max()))\n",
    "plt.colorbar(format=mtick.PercentFormatter())\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "ax.set_xticks(np.linspace(0,Nstrikes-1,Nstrikes))\n",
    "ax.set_xticklabels(strikes)\n",
    "ax.set_yticks(np.linspace(0,Nmaturities-1,Nmaturities))\n",
    "ax.set_yticklabels(maturities)\n",
    "plt.xlabel(\"Strike\",fontsize=15,labelpad=5)\n",
    "plt.ylabel(\"Maturity\",fontsize=15,labelpad=5)\n",
    "ax=plt.subplot(2,3,4)\n",
    "err1 = np.sqrt(np.mean(err_mat[bad_idx,:,:],axis=0))\n",
    "plt.title(\"RMSE\",fontsize=15,y=1.04)\n",
    "plt.imshow(err1)#,norm=LogNorm(vmin=err1.min(), vmax=err1.max()))\n",
    "plt.colorbar(format=mtick.PercentFormatter())\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "ax.set_xticks(np.linspace(0,Nstrikes-1,Nstrikes))\n",
    "ax.set_xticklabels(strikes)\n",
    "ax.set_yticks(np.linspace(0,Nmaturities-1,Nmaturities))\n",
    "ax.set_yticklabels(maturities)\n",
    "plt.xlabel(\"Strike\",fontsize=15,labelpad=5)\n",
    "plt.ylabel(\"Maturity\",fontsize=15,labelpad=5)\n",
    "ax=plt.subplot(2,3,5)\n",
    "err2 = np.std(err_mat[bad_idx,:,:],axis = 0)\n",
    "plt.title(\"Std MSE\",fontsize=15,y=1.04)\n",
    "plt.imshow(err2)#,norm=LogNorm(vmin=err2.min(), vmax=err2.max()))\n",
    "plt.colorbar(format=mtick.PercentFormatter())\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "ax.set_xticks(np.linspace(0,Nstrikes-1,Nstrikes))\n",
    "ax.set_xticklabels(strikes)\n",
    "ax.set_yticks(np.linspace(0,Nmaturities-1,Nmaturities))\n",
    "ax.set_yticklabels(maturities)\n",
    "plt.xlabel(\"Strike\",fontsize=15,labelpad=5)\n",
    "plt.ylabel(\"Maturity\",fontsize=15,labelpad=5)\n",
    "ax=plt.subplot(2,3,6)\n",
    "err3 = np.max(err_mat[bad_idx,:,:],axis = 0)\n",
    "plt.title(\"Maximum MSE\",fontsize=15,y=1.04)\n",
    "plt.imshow(err3)#,norm=LogNorm(vmin=err3.min(), vmax=err3.max()))\n",
    "plt.colorbar(format=mtick.PercentFormatter())\n",
    "ax.set_xticks(np.linspace(0,Nstrikes-1,Nstrikes))\n",
    "ax.set_xticklabels(strikes)\n",
    "ax.set_yticks(np.linspace(0,Nmaturities-1,Nmaturities))\n",
    "ax.set_yticklabels(maturities)\n",
    "plt.xlabel(\"Strike\",fontsize=15,labelpad=5)\n",
    "plt.ylabel(\"Maturity\",fontsize=15,labelpad=5)\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CNN as  Decoder/Inverse Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping for cnn purposes\n",
    "y_train_trafo2 = y_train_trafo.reshape((Ntrain,Nmaturities,Nstrikes,1))\n",
    "y_test_trafo2 = y_test_trafo.reshape((Ntest,Nmaturities,Nstrikes,1))\n",
    "y_val_trafo2 = y_val_trafo.reshape((Nval,Nmaturities,Nstrikes,1))\n",
    "X_val_trafo2 = X_val_trafo.reshape((Nval,Nparameters))\n",
    "X_train_trafo2 = X_train_trafo.reshape((Ntrain,Nparameters))\n",
    "X_test_trafo2 = X_test_trafo.reshape((Ntest,Nparameters))\n",
    "\"\"\" old structure with multi-purpose network \n",
    "input1 = Input(shape = (7,9,1))\n",
    "x1 = Conv2D(64, kernel_size=3, activation='relu')(input1)\n",
    "x2 = Conv2D(64, kernel_size=3, activation='relu')(x1)\n",
    "x3 = Flatten()(x2)\n",
    "x4 = Dense(50, activation = 'elu')(x3)\n",
    "seq1 = Dense(1, activation = 'linear',use_bias=True)(x4)\n",
    "seq2 = Dense(1, activation = 'linear',use_bias=True)(x4)\n",
    "seq3 = Dense(1, activation = 'linear',use_bias=True)(x4)\n",
    "seq4 = Dense(1, activation = 'linear',use_bias=True)(x4)\n",
    "seq5 = Dense(1, activation = 'linear',use_bias=True)(x4)\n",
    "out1 = keras.layers.merge.concatenate([seq1, seq2, seq3,seq4,seq5], axis=-1)\n",
    "NN2 = Model(inputs=input1, outputs=out1)\n",
    "\"\"\"\n",
    "NN2 = Sequential() \n",
    "NN2.add(InputLayer(input_shape=(Nmaturities,Nstrikes,1)))\n",
    "NN2.add(Conv2D(64,(3, 3),padding='valid',strides =(1,1),activation ='tanh'))\n",
    "NN2.add(Conv2D(64,(2, 2),padding='valid',strides =(1,1),activation ='tanh'))\n",
    "NN2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "NN2.add(Conv2D(64,(2, 2),padding='valid',strides =(1,1),activation ='tanh'))\n",
    "NN2.add(ZeroPadding2D(padding=(1,1)))\n",
    "NN2.add(Conv2D(64,(2, 2),padding='valid',strides =(1,1),activation ='tanh'))\n",
    "NN2.add(ZeroPadding2D(padding=(1,1)))\n",
    "NN2.add(Conv2D(64,(2, 2),padding='valid',strides =(1,1),activation ='tanh'))\n",
    "NN2.add(Conv2D(64,(2, 2),padding='valid',strides =(1,1),activation ='tanh'))\n",
    "NN2.add(ZeroPadding2D(padding=(1,1)))\n",
    "NN2.add(Conv2D(64,(2, 2),padding='valid',strides =(1,1),activation ='tanh'))\n",
    "NN2.add(ZeroPadding2D(padding=(1,1)))\n",
    "NN2.add(Conv2D(64,(2, 2),padding='valid',strides =(1,1),activation ='tanh'))\n",
    "\n",
    "NN2.add(Flatten())\n",
    "NN2.add(Dense(5,activation = 'linear',use_bias=True))\n",
    "NN2.summary()\n",
    "#NN2.compile(loss = root_relative_mean_squared_error, optimizer = \"adam\",metrics=[\"MAPE\",\"MSE\"])\n",
    "NN2.compile(loss =\"MSE\", optimizer = \"adam\",metrics=[\"MAPE\", root_relative_mean_squared_error])\n",
    "\n",
    "NN2.fit(y_train_trafo2,X_train_trafo2, batch_size=50, validation_data = (y_val_trafo2,X_val_trafo2),\n",
    "        epochs = 50, verbose = True, shuffle=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Results\n",
    "Take care these results are on scaled parameter values and not rescaled yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = NN2.predict(y_test_trafo2)\n",
    "error = np.zeros((Ntest,Nparameters))\n",
    "for i in range(Ntest):\n",
    "    error[i,:] =  np.abs((X_test_trafo2[i,:]-prediction[i,:])/X_test_trafo2[i,:])\n",
    "prediction_std = np.std(prediction,axis=0)\n",
    "err1 = np.mean(error,axis = 0)\n",
    "err_std = np.std(error,axis = 0)\n",
    "idx = np.argsort(error[:,0], axis=None)\n",
    "good_idx = idx[:-100]\n",
    "plt.boxplot(np.log(error))\n",
    "plt.xticks([1, 2, 3,4,5], ['w','a','b','g*','h0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing the performace of the AutoEncoder/Decoder Combination\n",
    "We test how the two previously trained NN work together. First, HNG-Vola surfaces are used to predict the underlying parameters with NN2. Those predictions are fed into NN1 to get Vola-Surface again. The results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_trafo = prediction.reshape((Ntest,Nparameters,1,1))\n",
    "forecast = NN1.predict(prediction_trafo).reshape(Ntest,Nmaturities,Nstrikes)\n",
    "y_true_test = y_test_trafo2.reshape(Ntest,Nmaturities,Nstrikes)\n",
    "\n",
    "# Example Plots\n",
    "X = strikes\n",
    "Y = maturities\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from matplotlib import cm\n",
    "import random\n",
    "sample_idx = random.randint(0,len(y_test))\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "#ax.contour3D(X, Y, Z, 50, cmap='binary')\n",
    "ax.plot_surface(X, Y, y_true_test[sample_idx,:,:], rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.plot_surface(X, Y, forecast[sample_idx,:,:] , rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('Strikes')\n",
    "ax.set_ylabel('Maturities')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
