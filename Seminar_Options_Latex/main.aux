\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Blanka}
\citation{Blanka}
\citation{Blanka}
\citation{Blanka}
\citation{HestonNandi}
\citation{EngleGARCH}
\citation{HestonNandi97}
\citation{HestonNandi}
\citation{GARCH}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Recap: The GARCH-Model of Heston and Nandi}{3}{section.2}}
\newlabel{sec:HNG}{{2}{3}{Recap: The GARCH-Model of Heston and Nandi}{section.2}{}}
\newlabel{eq:HNG}{{1}{3}{Recap: The GARCH-Model of Heston and Nandi}{equation.2.1}{}}
\citation{Book}
\citation{Blanka}
\citation{Blanka}
\citation{Blanka}
\citation{HestonNandi}
\newlabel{eq:pricing}{{2}{4}{Recap: The GARCH-Model of Heston and Nandi}{equation.2.2}{}}
\citation{Blanka}
\citation{Hernandez}
\citation{Blanka}
\citation{Blanka}
\@writefile{toc}{\contentsline {section}{\numberline {3}Deep Learning and Calibration Approach by Horvath et al.\cite  {Blanka}}{5}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Formalisation of the Deep Learning Approach}{5}{subsection.3.1}}
\newlabel{eq:param}{{3}{5}{Formalisation of the Deep Learning Approach}{equation.3.3}{}}
\citation{Blanka}
\citation{Hernandez}
\citation{Blanka}
\citation{Blanka}
\citation{Blanka}
\citation{Blanka}
\citation{Blanka}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The two step approach - Image-based implicit learning}{6}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Neural Network architecture}{6}{subsection.3.3}}
\newlabel{sec:NN_arch}{{3.3}{6}{Neural Network architecture}{subsection.3.3}{}}
\citation{Blanka}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Calibration}{7}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology and Model Choice}{7}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Choice of scenarios}{7}{subsection.4.1}}
\newlabel{sec:scenarios}{{4.1}{7}{Choice of scenarios}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Scenarios based on Maximum Likelihood estimators}{7}{subsubsection.4.1.1}}
\newlabel{sec:setupmle}{{4.1.1}{7}{Scenarios based on Maximum Likelihood estimators}{subsubsection.4.1.1}{}}
\citation{HestonNandi}
\citation{HestonNandi}
\citation{Book}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Scenarios based on low relative errors}{8}{subsubsection.4.1.2}}
\newlabel{sec:setupomega20}{{4.1.2}{8}{Scenarios based on low relative errors}{subsubsection.4.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Scenarios based on small \relax \mathversion  {bold}{$\gamma ^*$}}{8}{subsubsection.4.1.3}}
\newlabel{sec:setupsmallg}{{4.1.3}{8}{Scenarios based on small \boldmath {$\gamma ^*$}}{subsubsection.4.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of frequency distributions of implied volatilities of the different datasets\relax }}{8}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:vol_dist}{{1}{8}{Comparison of frequency distributions of implied volatilities of the different datasets\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}A simple approach on "How to involve real data"}{9}{subsection.4.2}}
\newlabel{sec:real_data}{{4.2}{9}{A simple approach on "How to involve real data"}{subsection.4.2}{}}
\newlabel{eq:max}{{4}{9}{A simple approach on "How to involve real data"}{equation.4.4}{}}
\newlabel{eq:mle}{{5}{9}{A simple approach on "How to involve real data"}{equation.4.5}{}}
\newlabel{eq:rekursiv}{{6}{9}{A simple approach on "How to involve real data"}{equation.4.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Rolling estimation of Heston and Nandi between 2012 and 2015 on S\&P500\relax }}{9}{table.caption.3}}
\newlabel{tab:resultsMLE}{{1}{9}{Rolling estimation of Heston and Nandi between 2012 and 2015 on S\&P500\relax }{table.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Rolling estimation of Heston and Nandi between 2012 and 2015 on S\&P500\relax }}{9}{figure.caption.4}}
\newlabel{fig:paramsMLE}{{2}{9}{Rolling estimation of Heston and Nandi between 2012 and 2015 on S\&P500\relax }{figure.caption.4}{}}
\citation{Blanka}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Call prices of 2015 and fitted price surface\relax }}{10}{figure.caption.5}}
\newlabel{fig:real_surf}{{3}{10}{Call prices of 2015 and fitted price surface\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{10}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Volatility surfaces}{10}{subsection.5.1}}
\newlabel{sec:vola_results}{{5.1}{10}{Volatility surfaces}{subsection.5.1}{}}
\citation{Blanka}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces $90\%$ Maximum Likelihood confidence interval - Relative errors of the neural network predicted volatilities compared to true volatilities in the test set\relax }}{11}{figure.caption.6}}
\newlabel{fig:MLE_NN_rel_err}{{4}{11}{$90\%$ Maximum Likelihood confidence interval - Relative errors of the neural network predicted volatilities compared to true volatilities in the test set\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces $90\%$ Maximum Likelihood confidence interval - Relative errors of the parameters after calibration with Levenberg-Marquardt compared to true parameters in the test set\relax }}{11}{figure.caption.7}}
\newlabel{fig:MLE_par_sen}{{5}{11}{$90\%$ Maximum Likelihood confidence interval - Relative errors of the parameters after calibration with Levenberg-Marquardt compared to true parameters in the test set\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces $90\%$ Maximum Likelihood confidence interval - Comparison of neural network predicted volatilites and true volatilites in the test set\relax }}{12}{figure.caption.8}}
\newlabel{fig:MLE_smile}{{6}{12}{$90\%$ Maximum Likelihood confidence interval - Comparison of neural network predicted volatilites and true volatilites in the test set\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Best fit - Relative errors of the neural network predicted volatilities compared to true volatilities in the test set\relax }}{12}{figure.caption.9}}
\newlabel{fig:low_err_NN_rel_err}{{7}{12}{Best fit - Relative errors of the neural network predicted volatilities compared to true volatilities in the test set\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Price surfaces}{12}{subsection.5.2}}
\newlabel{sec:price_surf}{{5.2}{12}{Price surfaces}{subsection.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Best fit - Comparison of neural network predicted volatilites and true volatilites in the test set\relax }}{13}{figure.caption.10}}
\newlabel{fig:low_err_smile}{{8}{13}{Best fit - Comparison of neural network predicted volatilites and true volatilites in the test set\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Best fit - Relative errors of the parameters after calibration with Levenberg-Marquardt compared to true parameters in the test set\relax }}{13}{figure.caption.11}}
\newlabel{fig:low_err_par_sen}{{9}{13}{Best fit - Relative errors of the parameters after calibration with Levenberg-Marquardt compared to true parameters in the test set\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Small $\gamma ^*$ - Relative errors of the neural network predicted volatilities compared to true volatilities in the test set\relax }}{14}{figure.caption.12}}
\newlabel{fig:Small_g_NN_rel_err}{{10}{14}{Small $\gamma ^*$ - Relative errors of the neural network predicted volatilities compared to true volatilities in the test set\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Small $\gamma ^*$ - comparison of neural network predicted volatilites and true volatilites in the test set\relax }}{14}{figure.caption.13}}
\newlabel{fig:Small_g_smile}{{11}{14}{Small $\gamma ^*$ - comparison of neural network predicted volatilites and true volatilites in the test set\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Performance in Comparsion to Black-Scholes}{14}{subsubsection.5.2.1}}
\newlabel{sec:bs_results}{{5.2.1}{14}{Performance in Comparsion to Black-Scholes}{subsubsection.5.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Small $\gamma ^*$ - comparison of volatility surface approximation by neural network to true surface\relax }}{15}{figure.caption.14}}
\newlabel{fig:Small_g_vola_surface}{{12}{15}{Small $\gamma ^*$ - comparison of volatility surface approximation by neural network to true surface\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Small $\gamma ^*$ - Relative errors of the parameters after calibration with Levenberg-Marquardt compared to true parameters in the test set\relax }}{15}{figure.caption.15}}
\newlabel{fig:Small_g_par_sen}{{13}{15}{Small $\gamma ^*$ - Relative errors of the parameters after calibration with Levenberg-Marquardt compared to true parameters in the test set\relax }{figure.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Performance Analysis - RMSE in each setup\relax }}{15}{table.caption.18}}
\newlabel{tab:bs_rmse}{{2}{15}{Performance Analysis - RMSE in each setup\relax }{table.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Small $\gamma ^*$ - Relative errors of the neural network predicted option prices compared to true prices in the test set\relax }}{16}{figure.caption.16}}
\newlabel{fig:Small_g_Price_NN_rel_err}{{14}{16}{Small $\gamma ^*$ - Relative errors of the neural network predicted option prices compared to true prices in the test set\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Small $\gamma ^*$ - comparison of option price surface approximation by neural network to true price surface\relax }}{16}{figure.caption.17}}
\newlabel{fig:Small_g_price_surface}{{15}{16}{Small $\gamma ^*$ - comparison of option price surface approximation by neural network to true price surface\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Outlook: "How to involve real data"}{16}{subsection.5.3}}
\newlabel{sec:results_sp500}{{5.3}{16}{Outlook: "How to involve real data"}{subsection.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Relative errors of the neural network predicted option prices compared to true S\&P500 prices in 2013\relax }}{17}{figure.caption.19}}
\newlabel{fig:MLE_Price_NN_rel_err}{{16}{17}{Relative errors of the neural network predicted option prices compared to true S\&P500 prices in 2013\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Robustness}{17}{subsection.5.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Sensitivity towards mispricing}{17}{subsubsection.5.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Robustness test for the best fit dataset (cf. Section \ref  {sec:setupomega20}) - pure dataset vs. dataset with $\pm 1\%$ noise in the train set volatilities\relax }}{17}{figure.caption.20}}
\newlabel{fig:MLE_Price_NN_rel_err_2}{{17}{17}{Robustness test for the best fit dataset (cf. Section \ref {sec:setupomega20}) - pure dataset vs. dataset with $\pm 1\%$ noise in the train set volatilities\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}Sensitivity towards training set size}{17}{subsubsection.5.4.2}}
\newlabel{sec:robust_size}{{5.4.2}{17}{Sensitivity towards training set size}{subsubsection.5.4.2}{}}
\citation{Blanka}
\citation{Blanka}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Robustnesstest - Change in size of training set\relax }}{18}{figure.caption.21}}
\newlabel{fig:trainset_sensitivity}{{18}{18}{Robustnesstest - Change in size of training set\relax }{figure.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of weights in Neural Nets - 2-Sample-KS-test  $\hspace  {0.7cm}^*\delimiter "026E30F ^{**}\delimiter "026E30F ^{***}$ corresponds to significance at $10\%\delimiter "026E30F 5\%\delimiter "026E30F 1\%$.\relax }}{18}{table.caption.22}}
\newlabel{tab:weights_size}{{3}{18}{Comparison of weights in Neural Nets - 2-Sample-KS-test\\ $\hspace {0.7cm}^*\backslash ^{**}\backslash ^{***}$ corresponds to significance at $10\%\backslash 5\%\backslash 1\%$.\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Challenges and Discussion}{18}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{18}{section.7}}
\bibcite{Blanka}{1}
\bibcite{HestonNandi}{2}
\bibcite{EngleGARCH}{3}
\bibcite{HestonNandi97}{4}
\bibcite{GARCH}{5}
\bibcite{Book}{6}
\bibcite{Hernandez}{7}
\bibcite{BlankaRef37}{8}
\bibcite{LyudmilaJuanPaplo}{9}
\bibcite{PavelMaster}{10}
\bibcite{StudyHestonNandi}{11}
\@writefile{toc}{\contentsline {section}{\numberline {A}Further Volatility Plots}{20}{appendix.A}}
\newlabel{sec:app_vola_plots}{{A}{20}{Further Volatility Plots}{appendix.A}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces $90\%$ Maximum Likelihood confidence interval - Empirical CDF of parameter relative error and empirical CDF of implied volatility surface RMSE\relax }}{20}{figure.caption.25}}
\newlabel{fig:MLE_CDF}{{19}{20}{$90\%$ Maximum Likelihood confidence interval - Empirical CDF of parameter relative error and empirical CDF of implied volatility surface RMSE\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Best fit - Empirical CDF of parameter relative error and empirical CDF of implied volatility surface RMSE\relax }}{20}{figure.caption.26}}
\newlabel{fig:low_err_CDF}{{20}{20}{Best fit - Empirical CDF of parameter relative error and empirical CDF of implied volatility surface RMSE\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Best fit - Empirical CDF of parameter relative error and empirical CDF of implied volatility surface RMSE\relax }}{20}{figure.caption.27}}
\newlabel{fig:small_g_CDF}{{21}{20}{Best fit - Empirical CDF of parameter relative error and empirical CDF of implied volatility surface RMSE\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Further Robustness Test}{21}{appendix.B}}
\newlabel{app:robust_size}{{B}{21}{Further Robustness Test}{appendix.B}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces 2-Sample-KS-test - Comparison of weights in Neural Nets\relax }}{21}{table.caption.28}}
\newlabel{tab:weights_size_20p}{{4}{21}{2-Sample-KS-test - Comparison of weights in Neural Nets\relax }{table.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Robustnesstest - Change in size of training set (20\%)\relax }}{21}{figure.caption.29}}
\newlabel{fig:trainset_sensitivity_20p}{{22}{21}{Robustnesstest - Change in size of training set (20\%)\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Black Scholes Comparison}{21}{appendix.C}}
\newlabel{app:bs_rmse}{{C}{21}{Black Scholes Comparison}{appendix.C}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces RMSE of Neural Net (blue) and Blacks Scholes (orange) on test set \relax }}{21}{figure.caption.30}}
\newlabel{fig:rmse_bs_net}{{23}{21}{RMSE of Neural Net (blue) and Blacks Scholes (orange) on test set \relax }{figure.caption.30}{}}
